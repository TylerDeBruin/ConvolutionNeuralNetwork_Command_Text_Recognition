{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17eb3d45-191f-47df-916f-32ad1256a8e1",
   "metadata": {},
   "source": [
    "# CS 4964 - Final Project: Command Word Audio\n",
    "<div style=\"text-align: right; font-weight: bold;\"> Tyler DeBruin </div>\n",
    "<div style=\"text-align: right; font-weight: bold;\"> Nolan Angerbauer </div>\n",
    "<br>\n",
    "<div style=\"text-align: right; font-weight: bold;\"> 3/28/2024 </div>\n",
    "<br>\n",
    "\n",
    "\n",
    "<div style=\"text-align: center; font-weight: bold;\"> Final Project: Command Word Audio </div>\n",
    "\n",
    "### Abstract\n",
    "\n",
    "Utilizing Apache Spark, and a Command Word dataset provided by Huggingface.co we will build\n",
    "and train a machine learning model that can differentiate command words from non-command words, or\n",
    "silence and white noise. We provide a mechanism to forward audio into the model, and provide inference\n",
    "on the output command word.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "The dataset we will be using is from Huggingface.co. \n",
    "\n",
    "Repository: https://huggingface.co/datasets/speech_commands\n",
    "<br>\n",
    "As Per HuggingFace:\n",
    "<br>\n",
    "##### Language\n",
    "English (BCP-47 en)\n",
    "<br>\n",
    "##### Collection\n",
    "The audio files were collected using crowdsourcing. The goal was to gather examples of people speaking single-word commands, rather than conversational sentences, so they were prompted for individual words over the course of a five minute session. The dataset consists of people who have donated their voice online. \n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c41cb2-8d43-4d4b-9247-149ef6e1ae63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "from speech_commands import SpeechCommands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb540e85-268c-4244-9325-87db7e7f2ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 463M/463M [00:09<00:00, 47.4MB/s] \n",
      "Downloading data: 100%|██████████| 460M/460M [00:09<00:00, 47.2MB/s] \n",
      "Downloading data: 100%|██████████| 462M/462M [00:10<00:00, 42.5MB/s] \n",
      "Downloading data: 100%|██████████| 465M/465M [00:11<00:00, 39.5MB/s] \n",
      "Downloading data: 100%|██████████| 456M/456M [00:11<00:00, 39.3MB/s] \n",
      "Downloading data: 100%|██████████| 168M/168M [00:04<00:00, 40.9MB/s] \n",
      "Downloading data: 100%|██████████| 292M/292M [00:10<00:00, 28.3MB/s] \n",
      "Downloading data: 100%|██████████| 143M/143M [00:03<00:00, 36.6MB/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc5fa36f83047758f64ae8e3c34d243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/84848 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ae353d870b4fd0b514118e17217bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/9982 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8076656b5dc245f9b4cb353022bdfa4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4890 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"speech_commands\", \"v0.02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6066bcfb-80e7-4444-91a6-fe6dcee601ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'label', 'is_unknown', 'speaker_id', 'utterance_id'],\n",
       "        num_rows: 84848\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['file', 'audio', 'label', 'is_unknown', 'speaker_id', 'utterance_id'],\n",
       "        num_rows: 9982\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file', 'audio', 'label', 'is_unknown', 'speaker_id', 'utterance_id'],\n",
       "        num_rows: 4890\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62fabdc1-97e5-4c64-9318-0dac7bb1df94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'backward/2356b88d_nohash_0.wav',\n",
       " 'audio': {'path': '2356b88d_nohash_0.wav',\n",
       "  'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00012207,\n",
       "         -0.00015259, -0.00012207]),\n",
       "  'sampling_rate': 16000},\n",
       " 'label': 30,\n",
       " 'is_unknown': True,\n",
       " 'speaker_id': '2356b88d',\n",
       " 'utterance_id': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b0cceb-869e-49c6-982c-95621df7f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Final Project\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2133f70-7ce6-4cb9-baa7-8bafbe51a11c",
   "metadata": {},
   "source": [
    "### Convolution Neural Network\n",
    "https://en.wikipedia.org/wiki/Convolutional_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d89021-7358-4c9b-91dc-e36db45a7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4310dfe8-63b2-4fd7-a7ec-2070ed19b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommandWordCNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81937929-9ab8-41dd-a748-155b21204b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "commandWord = CommandWordCNN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
